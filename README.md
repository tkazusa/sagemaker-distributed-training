# Sagemakerでの分散学習

- [PARALLELIZED DATA DISTRIBUTION](https://sagemaker-workshop.com/builtin/parallelized.html)
- [Amazon SageMaker Tensorflow ハンズオン](https://github.com/shokout/handson-201812)


### [TensorFlow 分散トレーニングオプション](https://github.com/aws-samples/amazon-sagemaker-script-mode/blob/master/tf-distribution-options/tf-distributed-training.ipynb)
- Tensorflowのネイティブパラメーターサーバーを用いた分散学習。
- 

- [Amazon SageMaker の Horovod またはパラメータサーバーでTensorFlow 分散トレーニングを簡単に起動する](https://aws.amazon.com/jp/blogs/news/launching-tensorflow-distributed-training-easily-with-horovod-or-parameter-servers-in-amazon-sagemaker/)
- [Sagemaker Distributed Training with Parameter Server and Horovod](https://github.com/aws-samples/sagemaker-horovod-distributed-training)
- [Amazon SageMaker TensorFlow のスクリプトモードを使用した Horovod 分散トレーニング](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/tensorflow_script_mode_horovod/tensorflow_script_mode_horovod.ipynb)


# 参考
- [Power Machine Learning at Scale](https://d1.awsstatic.com/whitepapers/aws-power-ml-at-scale.pdf)
